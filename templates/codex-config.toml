# ~/.codex/config.toml â€” created by codex-1up
# Adjust to your liking. See Codex CLI docs for full options.
#
# This template is aligned to Codex CLI (codex-rs) v0.101 config keys.

# Core (root defaults)
model = "gpt-5.3-codex"
approval_policy = "on-request"       # untrusted|on-request|on-failure|never (on-failure is deprecated)
sandbox_mode   = "workspace-write"   # read-only|workspace-write|danger-full-access
profile = "balanced"                 # active profile: balanced|safe|yolo

# Web search mode: disabled|cached|live (v0.88+).
# Root `web_search` is a fallback default; `profiles.<name>.web_search` overrides it.
# `live` requires network access when using the workspace-write sandbox.
web_search = "live"

# If you enable under-development features (e.g. collab), Codex may warn on startup.
# Set this to true to hide that warning.
# suppress_unstable_features_warning = true

# Credential storage (recommended: auto)
cli_auth_credentials_store = "auto"      # auto|file|keyring
mcp_oauth_credentials_store = "auto"     # auto|file|keyring

# Optional: make citations clickable in your editor.
# file_opener = "cursor"                 # cursor|vscode|vscode-insiders|windsurf|none

# Optional: personality framing for model responses.
# personality = "none"                   # none|friendly|pragmatic
#
# If personalities ever look "stuck" or "not applying", try clearing the remote models cache:
#   rm -f ~/.codex/models_cache.json

# Reasoning output controls (root keys; default false)
show_raw_agent_reasoning = true
hide_agent_reasoning = false

# Extra settings that only apply when `sandbox_mode = "workspace-write"`.
[sandbox_workspace_write]
# Allow the command being run inside the sandbox to make outbound network
# requests. Disabled by default; enable only if you need live web search or MCP.
network_access = true

# UI & notifications (can be toggled by installer)
[tui]
# Desktop notifications from the TUI: boolean or filtered list. Defaults to true in Codex.
# Examples: true | ["agent-turn-complete", "approval-requested"]
notifications = false
# Alternate screen mode: auto|always|never (use "never" for scrollback-friendly terminals)
alternate_screen = "auto"

# Tools (not feature flags)
[tools]
view_image = true

# Feature flags (advanced). Prefer leaving unset (Codex will use sensible defaults).
# /experimental menu toggles currently include:
# - collab (Sub-agents)
# - apps
# - use_linux_sandbox_bwrap (Linux only)
# - prevent_idle_sleep (macOS only)
[features]
# collab = false          # Sub-agents (requires restart)
# apps = false            # Enable ChatGPT Apps (connectors) via "$" and /apps (requires restart)
# use_linux_sandbox_bwrap = false # Bubblewrap sandbox (Linux only; requires restart)
# prevent_idle_sleep = false # Prevent system sleep while running (macOS only; requires restart)
# unified_exec = false    # Background terminal - run long-running commands in background
# shell_snapshot = false  # Snapshot shell env to speed up commands
# steer = false           # Enter submits, Tab queues messages
# personality = false     # Enable personality selection UI (requires restart)
# collaboration_modes = false # Enable Plan/Pair/Execute collaboration modes (requires restart)

# ---- Profiles (override only what differs from root) -----------------------

[profiles.balanced]
approval_policy = "on-request"
sandbox_mode = "workspace-write"
model = "gpt-5.3-codex"
model_reasoning_effort = "high"
# NOTE: gpt-5.3-codex-spark does not support reasoning summaries. If you use a *-spark model, set:
#   model_reasoning_summary = "none"
model_reasoning_summary = "detailed"
web_search = "cached"

[profiles.safe]
approval_policy = "untrusted"
sandbox_mode = "read-only"
model = "gpt-5.3-codex"
model_reasoning_effort = "medium"
model_reasoning_summary = "detailed"
web_search = "disabled"

[profiles.yolo]
approval_policy = "never"
sandbox_mode = "danger-full-access"
model = "gpt-5.3-codex"
model_reasoning_effort = "high"
model_reasoning_summary = "detailed"
web_search = "live"
